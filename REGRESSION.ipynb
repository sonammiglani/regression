{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# REGRESSION ASSIGNMENT QUESTIONS\n",
        "\n",
        "# 1. What is Simple Linear Regression?\n",
        "Simple Linear Regression models the relationship between two variables: one independent variable (X) and one dependent variable (Y), using the equation:\n",
        "  **Y = mX + c**,\n",
        "where **m** is the slope and **c** is the intercept.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "* Linearity\n",
        "* Independence of errors\n",
        "* Homoscedasticity (constant variance of errors)\n",
        "* Normality of residuals\n",
        "* No (or minimal) multicollinearity (not relevant with only one X)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 3. What does the coefficient *m* represent in Y = mX + c?\n",
        "The **slope (m)** shows how much Y changes for a one-unit increase in X.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 4. What does the intercept *c* represent in Y = mX + c?\n",
        "The **intercept (c)** is the predicted value of Y when X = 0.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 5. How do we calculate the slope *m* in Simple Linear Regression?\n",
        "$$\n",
        "m = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sum{(x_i - \\bar{x})^2}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 6. What is the purpose of the least squares method?\n",
        "It minimizes the **sum of squared residuals** (differences between observed and predicted values).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 7. How is R² interpreted in Simple Linear Regression?\n",
        "R² measures the proportion of variance in Y explained by X.\n",
        "\n",
        "* R² = 1: perfect fit\n",
        "* R² = 0: model explains none of the variance\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 8. What is Multiple Linear Regression?\n",
        "It models the relationship between one dependent variable and **two or more independent variables**:\n",
        "  **Y = b₀ + b₁X₁ + b₂X₂ + ... + bₙXₙ**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 9.what is the Main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "* **Simple:** One independent variable\n",
        "* **Multiple:** Two or more independent variables\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 10. what are the Key assumptions of Multiple Linear Regression?\n",
        "\n",
        "* Linearity\n",
        "* Independence of errors\n",
        "* Homoscedasticity\n",
        "* Normality of residuals\n",
        "* No multicollinearity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 11. What is heteroscedasticity?\n",
        "Unequal variance of residuals across levels of an independent variable. It leads to inefficient estimates and biased standard errors.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "* Remove/reduce correlated features\n",
        "* Use **Principal Component Analysis (PCA)**\n",
        "* Use **regularization** (Ridge/Lasso)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 13.What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "* **One-Hot Encoding**\n",
        "* **Label Encoding** (only when order matters)\n",
        "* **Binary Encoding**, **Target Encoding** (advanced)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "They model situations where the effect of one variable depends on another (e.g., **X₁ × X₂**).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "* **Simple:** Y when X = 0\n",
        "* **Multiple:** Y when all Xᵢ = 0 (often less interpretable)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "Indicates how the dependent variable is expected to change when an independent variable increases by one unit, holding others constant.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "It sets a **baseline value** for predictions. Though it may not always have a real-world interpretation, it anchors the regression line.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 18. What are the limitations of using R² as a sole measure of model performance?\n",
        "\n",
        "* Doesn’t penalize for overfitting\n",
        "* Can increase with more variables even if they aren’t meaningful\n",
        "* Doesn’t indicate whether predictors are statistically significant\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 19. How would you interpret a large standard error for a regression coefficient?\n",
        "Implies **low precision** in estimating that coefficient. It may not be statistically significant.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "Look for a **funnel shape** (residuals fan out/in). Addressing it is vital for valid statistical inference.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        "Suggests **overfitting** – you may have included irrelevant variables.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "* Required for algorithms using regularization\n",
        "* Helps interpret coefficients\n",
        "* Improves numerical stability\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 23. What is polynomial regression?\n",
        "It models a non-linear relationship by adding powers of the independent variable(s), e.g.:\n",
        "  **Y = b₀ + b₁X + b₂X² + ... + bₙXⁿ**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 24. How does polynomial regression differ from linear regression?\n",
        "Still **linear in parameters**, but includes **non-linear terms** (X², X³, etc.).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 25. When is polynomial regression used?\n",
        "When a **non-linear** relationship exists between X and Y but you still want to use linear models.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 26. What is the general equation for polynomial regression?\n",
        "  **Y = b₀ + b₁X + b₂X² + ... + bₙXⁿ**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 27. Can polynomial regression be applied to multiple variables?\n",
        "Yes — e.g., include **X₁²**, **X₁×X₂**, etc., but risk of **overfitting** increases.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 28.What are the limitations of polynomial regression?\n",
        "\n",
        "* Sensitive to outliers\n",
        "* Overfitting with high-degree polynomials\n",
        "* Difficult to interpret\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 29. - What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "* **Cross-validation (CV)**\n",
        "* **Adjusted R²**\n",
        "* **AIC/BIC**\n",
        "* **Residual plots**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# 30. Why is visualization important in polynomial regression?\n",
        "Helps you:\n",
        "\n",
        "* Understand the **shape** of the model\n",
        "* Identify **overfitting/underfitting**\n",
        "* Interpret predictions more intuitively\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 31. How to implement polynomial regression in Python?\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Example: Polynomial of degree 3\n",
        "model = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "btQtyk3mXAvw"
      }
    }
  ]
}